# -*- coding: utf-8 -*-
"""Text_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/107UNXACgaEdr9kQ2Af5QH8h8Zgi2d7KO
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function
import os
import itertools
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np      
from sklearn.metrics import  confusion_matrix
import keras
from keras import backend as K
from IPython.display import SVG
from keras.optimizers import Adam
from keras.utils import plot_model
from keras.models import Model, Sequential
from keras.callbacks import ReduceLROnPlateau
from keras.utils.vis_utils import model_to_dot
from keras.utils.generic_utils import get_custom_objects
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Input, Conv2D, Dense, Flatten, MaxPool2D
from keras.layers import Activation, Add, BatchNormalization, Dropout

import cv2
from imutils.object_detection import non_max_suppression
import pytesseract

!wget https://www.dropbox.com/s/6hq9q333ymgnhp4/helal.zip
!unzip "helal.zip"
!ls helal.zip

model = Sequential()
model.add(Conv2D(activation ='relu', input_shape = (128,128,3), filters=16, kernel_size=(8, 8), padding="SAME", strides=(1, 1)))
model.add(Conv2D(activation ='relu',filters=32, kernel_size=(8, 8), padding="SAME", strides=(1, 1)))
model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
#model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
#model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))

#model.add(Conv2D(activation ='relu',filters=32, kernel_size=(5, 5), padding="SAME", strides=(1, 1)))
#model.add(Conv2D(activation ='relu',filters=32, kernel_size=(5, 5), padding="SAME", strides=(1, 1)))
#model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
#model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
#model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
#model.add(BatchNormalization())
model.add(Conv2D(activation ='relu',filters=16, kernel_size=(5, 5), padding="SAME", strides=(1, 1)))
model.add(Conv2D(activation ='relu',filters=16, kernel_size=(5, 5), padding="SAME", strides=(1, 1)))
model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
#model.add(Conv2D(activation ='relu',filters=8, kernel_size=(3, 3), padding="SAME", strides=(1, 1)))
#model.add(Conv2D(activation ='relu',filters=8, kernel_size=(3, 3), padding="SAME", strides=(1,1)))
model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))

model.add(BatchNormalization())

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(.5))
model.add(Dense(units = 3, activation='softmax'))
model.summary()

optimizer = Adam(lr=0.001)
model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=["accuracy"])

train_datagen = ImageDataGenerator(
                                          rotation_range=40,
                                        width_shift_range=0.2,
                                        height_shift_range=0.2,
                                        rescale=1./255,
                                       shear_range=0.2,
                                        zoom_range=0.6,
                                       horizontal_flip=True,
                                        fill_mode='nearest')
    
    
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
                                                    'helal/train',
                                                    target_size=(128, 128),
                                                    batch_size=30,
                                                    color_mode='rgb',
                                                    class_mode='categorical')
    
validation_generator = test_datagen.flow_from_directory(
                                                        'helal/test',
                                                         target_size=(128,128),
                                                         batch_size=30,
                                                         color_mode='rgb',
                                                         class_mode='categorical')

learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',
                                            patience=1,
                                            verbose=1,
                                            factor=0.2,
                                            min_lr=0.000001)

history = model.fit_generator(
                        train_generator,
                        steps_per_epoch=555/30,
                        epochs=30,
                        validation_data=validation_generator,
                        validation_steps=50,
                        verbose=1,
                        callbacks=[learning_rate_reduction])

#Plot the loss and accuracy curves for training and validation
fig, ax = plt.subplots(2,1)
ax[0].plot(history.history['loss'], color='b', label="Training loss")
ax[0].plot(history.history['val_loss'], color='r', label="validation loss",axes =ax[0])
legend = ax[0].legend(loc='best', shadow=True)
ax[1].plot(history.history['acc'], color='b', label="Training accuracy")
ax[1].plot(history.history['val_acc'], color='r',label="Validation accuracy")
legend = ax[1].legend(loc='best', shadow=True)

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

def plot_confusion_matrix(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=False):
  
   

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(10, 8))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")


    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.show()
    
plot_confusion_matrix(confusion_matrix(validation_generator.classes, y_pred), target_names = ['horizonal_mb','resizeimage','vertical_mb'],cmap='BuGn')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import glob
import matplotlib
from matplotlib import pyplot as plt
import matplotlib.image as mpimg

import numpy as np
import imageio as im
from keras import models
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Dropout
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint

img_path = 'C:\Users\User\Desktop\o\opencv-text-detection\images\lebron_james.jpg'

img = image.load_img(img_path)
img_tensor = image.img_to_array(img)
img_tensor = np.expand_dims(img_tensor, axis=0)
img_tensor /= 255.

plt.imshow(img_tensor[0])
plt.show()

print(img_tensor.shape)

# predicting images
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)

images = np.vstack([x])
classes = model.predict_classes(images, batch_size=30)
print("Predicted class is:",classes)

layer_outputs = [layer.output for layer in model.layers[:14]] 
# Extracts the outputs of the top 12 layers

activation_model = models.Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input

activations = activation_model.predict(img_tensor)

first_layer_activation = activations[0]
print(first_layer_activation.shape)

plt.matshow(first_layer_activation[0, :, :, 2], cmap='viridis')

!pip install pytesseract

args = {"image":"../input/text-detection/example-images/Example-images/ex24.jpg", "east":"../input/text-detection/east_text_detection.pb", "min_confidence":0.5, "width":320, "height":320}

args['image']="../input/opencv-text-detection\images\lebron_james.jpg"
image = cv2.imread(args['image'])

#Saving a original image and shape
orig = image.copy()
(origH, origW) = image.shape[:2]

# set the new height and width to default 320 by using args #dictionary.  
(newW, newH) = (args["width"], args["height"])

#Calculate the ratio between original and new image for both height and weight. 
#This ratio will be used to translate bounding box location on the original image. 
rW = origW / float(newW)
rH = origH / float(newH)

# resize the original image to new dimensions
image = cv2.resize(image, (newW, newH))
(H, W) = image.shape[:2]

# construct a blob from the image to forward pass it to EAST model
blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
	(123.68, 116.78, 103.94), swapRB=True, crop=False)

# USAGE
# python text_detection.py --image images/lebron_james.jpg --east frozen_east_text_detection.pb

# import the necessary packages
from imutils.object_detection import non_max_suppression
import numpy as np
import argparse
import time
import cv2


ap.add_argument("-i", "--image", type=str,
	help="C:\Users\User\Desktop\o\opencv-text-detection\images\lebron_james.jpg")
ap.add_argument("-east", "--east", type=str,
	help="C:\Users\User\Desktop\o\opencv-text-detection\frozen_east_text_detection.pb")
ap.add_argument("-c", "0.1", type=float, default=0.5,
	help="minimum probability required to inspect a region")
ap.add_argument("-w", "128", type=int, default=320,
	help="resized image width (should be multiple of 32)")
ap.add_argument("-e", "128", type=int, default=320,
	help="resized image height (should be multiple of 32)")
args = vars(ap.parse_args()) 


image = cv2.imread(args["image"])

orig = image.copy()
(H, W) = image.shape[:2]


(newW, newH) = (args["width"], args["height"])
rW = W / float(newW)
rH = H / float(newH)


image = cv2.resize(image, (newW, newH))
(H, W) = image.shape[:2]


layerNames = [
	"feature_fusion/Conv_7/Sigmoid",
	"feature_fusion/concat_3"]


print("[INFO] loading EAST text detector...")
net = cv2.dnn.readNet(args["east"])


blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
	(123.68, 116.78, 103.94), swapRB=True, crop=False)
start = time.time()
net.setInput(blob)
(scores, geometry) = net.forward(layerNames)
end = time.time()


print("[INFO] text detection took {:.6f} seconds".format(end - start))


(numRows, numCols) = scores.shape[2:4]
rects = []
confidences = []


for y in range(0, numRows):

	scoresData = scores[0, 0, y]
	xData0 = geometry[0, 0, y]
	xData1 = geometry[0, 1, y]
	xData2 = geometry[0, 2, y]
	xData3 = geometry[0, 3, y]
	anglesData = geometry[0, 4, y]

	
	for x in range(0, numCols):
	
		if scoresData[x] < args["min_confidence"]:
			continue

	
		(offsetX, offsetY) = (x * 4.0, y * 4.0)


		angle = anglesData[x]
		cos = np.cos(angle)
		sin = np.sin(angle)

	
		h = xData0[x] + xData2[x]
		w = xData1[x] + xData3[x]

	
		endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))
		endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))
		startX = int(endX - w)
		startY = int(endY - h)


		rects.append((startX, startY, endX, endY))
		confidences.append(scoresData[x])

boxes = non_max_suppression(np.array(rects), probs=confidences)


for (startX, startY, endX, endY) in boxes:

	startX = int(startX * rW)
	startY = int(startY * rH)
	endX = int(endX * rW)
	endY = int(endY * rH)


	cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)


cv2.imshow("Text Detection", orig)
cv2.waitKey(0)











